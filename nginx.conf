events {
    worker_connections 1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    server {
        listen 8080;
        server_name _;
        root /usr/share/nginx/html;
        index index.html;

        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;


        # Proxy sitemap.xml to dynamic Supabase sitemap (MUST be before catch-all location)
        location = /sitemap.xml {
            proxy_pass https://psnzolounfwgvkupepxb.supabase.co/functions/v1/generate-sitemap;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            proxy_redirect off;
            # Set proper content type for XML
            add_header Content-Type "application/xml; charset=utf-8";
        }

        # Cache static assets
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # Proxy to Express server for crawlers (Express should run on port 3000)
        # Note: If using Express.js, ensure it runs on port 3000 and nginx proxies to it
        # If nginx is serving directly without Express, crawlers will get the React app
        location / {
            # Check if user agent is a crawler
            set $is_crawler 0;
            if ($http_user_agent ~* "(bot|crawler|spider|crawling|facebook|twitter|linkedin|whatsapp|telegram|discord|pinterest|chatgpt|chatgptbot|openai|claude|anthropic|gemini|google-ai|bing-ai|perplexity|ai|gpt)") {
                set $is_crawler 1;
            }
            
            # For crawlers, proxy to Express server on port 3000 (adjust if different)
            # Express will serve static HTML from Supabase Storage
            if ($is_crawler = 1) {
                proxy_pass http://127.0.0.1:3000;
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_set_header User-Agent $http_user_agent;
                break;
            }
            
            # For regular users, serve static files directly from nginx
            try_files $uri $uri/ /index.html;
        }

        # Handle API routes (if you have any backend endpoints)
        location /api/ {
            # Add your backend service URL here if needed
            # proxy_pass http://your-backend-service;
            return 404;
        }

        # Health check endpoint
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
